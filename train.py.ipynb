{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing an AI application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    " \n",
    "#  Matplotlib Information - Jupyter\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "#Importing torch essentials - Libraries\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F # or Function\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_paser():\n",
    "    paser = argparse.ArgumentParser(description='trainer file')\n",
    "    paser.add_argument('--data_dir', type=str, default='flowers', help='dataset directory')\n",
    "    paser.add_argument('--gpu', type=bool, default='True', help='True: gpu, False: cpu')\n",
    "    paser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    paser.add_argument('--epochs', type=int, default=10, help='num of epochs')\n",
    "    paser.add_argument('--arch', type=str, default='densenet201', help='architecture')\n",
    "    paser.add_argument('--hidden_layer', type=int, default=[25088, 102], help='hidden layer for layer')\n",
    "    paser.add_argument('--save_dir', type=str, default='checkpoint.pth', help='save train model to a file')\n",
    "    args = paser.parse_args()\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'flowers'\n",
    "#train_dir = data_dir + '/train'\n",
    "#valid_dir = data_dir + '/valid'\n",
    "#test_dir = data_dir + '/test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "#data_transforms = \n",
    "def procedure_data(train_dir, valid_dir, test_dir):\n",
    "    \n",
    "# TODO: Load the datasets with ImageFolder\n",
    "#image_datasets = \n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#dataloaders = \n",
    "\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(225),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                           [0.229,0.224,0.225])\n",
    "                                      ])\n",
    "    valid_transforms = transforms.Compose([transforms.Resize(299),\n",
    "                                       transforms.CenterCrop(255),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                           [0.229,0.224,0.225])\n",
    "                                      ])\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Resize(299),\n",
    "                                       transforms.CenterCrop(255),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,00.456,.406],\n",
    "                                                           [0.229,0.224,0.225])\n",
    "                                      ])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: Load the datasets with ImageFolder\n",
    "#image_datasets = \n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#dataloaders = \n",
    "#download and load the training data\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "#download and load the test data\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "\n",
    "#download and load the valid data\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "    validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "    \n",
    "    \n",
    "    return trainloader, testloader, validloader\n",
    "\n",
    "    print('dataloaders')   \n",
    "    \n",
    "    #image_datasets = [train_data, valid_data, test_data]\n",
    "    #dataloaders = [trainloader, validloader, testloader]\n",
    "    return trainloader, testloader, validloader, train_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_model(arch):\n",
    "   # Load pretrained_network\n",
    "    print('Please only select densenet201 or alexnet as pretrained model. By default densenet201 is selected!')\n",
    "    if arch == None or arch == 'densenet201':\n",
    "        load_model = models.densenet201(pretrained = True)\n",
    "#load_model.name = 'densenent201'\n",
    "        print('Current model: densenet201 loaded')\n",
    "    else:\n",
    "        load_model = models.alexnet (pretrained = True)\n",
    "        print('Current model: alexnet loaded')\n",
    "#model.name = alexnet\n",
    "\n",
    "    return load_model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tech_classifier(model, hidden_layer):\n",
    "    if hidden_layer == None:\n",
    "        hidden_layer = 25088\n",
    "    input = model.classifier[0].in_features\n",
    "\n",
    "    \n",
    "    \n",
    "    #Create classifier    \n",
    "    model.classifier = nn.Sequential(nn.Linear(25088, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(512, 256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(256, 102),\n",
    "                                nn.LogSoftmax(dim=1))\n",
    "#train the model\n",
    "    print('Model Running')\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, trainloader, validloader, gpu, model, optimizer, criterion):\n",
    "    accuracy = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    if type(epochs) == type(None):\n",
    "        epochs = 10\n",
    "    print(\"Epochs = 10\")\n",
    "\n",
    "\n",
    "    if gpu==True:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    steps = 0\n",
    "        \n",
    "       \n",
    "    \n",
    "    model.to(device)\n",
    "        \n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        \n",
    "        for inputs, labels in trainloader: ## check while, for, else\n",
    "        \n",
    "            steps += 1\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            #Gradients to zero\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            logps = model.forward(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            valid_loss = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "        with torch.no_grad():\n",
    "             for inputs, labels in validloader:\n",
    "                    \n",
    "                inputs, labels = inputs.to(device), labels.to(device)  #GPU\n",
    "                    \n",
    "                    \n",
    "                logps = model.forward(inputs)\n",
    "                    \n",
    "                valid_loss += criterion(logps, labels).item()\n",
    "                    \n",
    "                 # Accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss/len(['trainloader']):.3f}.. \"\n",
    "                f\"Validation loss: {valid_loss/len(['validloader']):.3f}.. \"\n",
    "                f\"Accuracy: {accuracy/len(['validloader']):.3f}.. \"\n",
    "                 )\n",
    "            \n",
    "            \n",
    "        running_loss = 0\n",
    "            \n",
    "        model.train()  #chaning back\n",
    "        \n",
    "        return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, testloader, gpu):\n",
    "\n",
    "    if gpu==True:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in testloader: ## check \n",
    "                     \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # forward pass with test data\n",
    "        logps = model.forward(inputs)\n",
    "\n",
    "        # accuracy\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equality = top_class == labels.view(*top_class.shape)\n",
    "        test_accuracy += equality.type(torch.FloatTensor).mean()\n",
    "\n",
    "    print(\"Test Accuracy: {:.3f}\".format(100 * (test_accuracy/len(testloader))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_check(model, train_dataset, arch, hidden_layer, epochs, optimizer, save_dir):   \n",
    "    \n",
    "    model.class_to_idx = train_data.class_to_idx\n",
    "\n",
    "    checkpoint = {'arch': arch,\n",
    "                  'hidden_layer': 25088,\n",
    "                  'output': 512,\n",
    "                  'mapping': model.class_to_idx,\n",
    "                  'epochs': epochs,\n",
    "                  'optimizer': optimizer.state_dict(),\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx\n",
    "                 }\n",
    "   \n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_dir DATA_DIR] [--gpu GPU] [--lr LR]\n",
      "                             [--epochs EPOCHS] [--arch ARCH]\n",
      "                             [--hidden_layers HIDDEN_LAYERS]\n",
      "                             [--save_dir SAVE_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\VHENDON1\\AppData\\Roaming\\jupyter\\runtime\\kernel-aca8658e-0c74-4a53-9ce9-24e5ffc9eff5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vhendon1\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    args = args_paser()\n",
    "\n",
    "    # Definition of image data directories\n",
    "    data_dir = 'flowers'\n",
    "    train_dir = data_dir + '/train'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    test_dir = data_dir + '/test'\n",
    "\n",
    "    # Define dataloaders\n",
    "    trainloader, testloader, validloader, train_dataset = process_data(train_dir, test_dir, valid_dir)\n",
    "\n",
    "    # Load pretrained model according to selection\n",
    "    model = what_model(args.arch)\n",
    "\n",
    "    # Freeze parameters of pretrained model to not backpropagate through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Define classifier for the model\n",
    "    model = tech_classifier(model, args.hidden_layers)\n",
    "\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    #print(device)\n",
    "\n",
    "    # Loss: negative log likelihood\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), learning_rate=args.lr)\n",
    "    print('Criterion and Optimizer !')\n",
    "\n",
    "    # Call of function to train the model\n",
    "    print('Model:')\n",
    "    #trained_model = train_model(args.epochs, trainloader, validloader, args.gpu, model, optimizer, criterion)\n",
    "\n",
    "    # Call of fucntion to validate the model\n",
    "    print('Validation - wait:')\n",
    "    #valid_model(trained_model, testloader, args.gpu)\n",
    "    #save_checkpoint(trained_model, train_dataset, args.arch, args.hidden_units, args.epochs, optimizer, args.save_dir)\n",
    "    print('Kaput!')\n",
    "\n",
    "if __name__ == '__main__': main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
